import numpy as np
from tqdm import tqdm
from torch.utils.data import Dataset
from utils import read_list, read_data, read_list_2d, read_data_2d, read_data_coarse
from utils.gen_coarse_mask_3d import perturb_seg,perturb_seg_erode,perturb_seg_dilate,perturb_seg_erode_mid,perturb_seg_erode_mid_slice
from data.gen_patches import find_float_boundary
from utils.config import Config
import torch
class DatasetAllTasks(Dataset):
    def __init__(self, split='train', 
                 num_cls=1, task="", 
                 repeat=None, 
                 transform=None, 
                 unlabeled=False, 
                 is_val=False, 
                 is_2d=False, 
                 is_coarse = True, 
                 need_norm = False,
                 full_path = None):
        if is_2d:
            self.ids_list = read_list_2d(split, task=task)
        else:
            self.ids_list = read_list(split, task=task)
        self.repeat = repeat
        self.task = task
        self.full_path = full_path
        if self.repeat is None:
            self.repeat = len(self.ids_list)
        print('total {} datas'.format(self.repeat))
        self.transform = transform
        self.unlabeled = unlabeled
        self.num_cls = num_cls
        self.is_val = is_val
        self.is_2d = is_2d
        self.is_coarse = is_coarse
        self.need_norm = need_norm
        # if self.is_val:
        #     self.data_list = {}
        #     for data_id in tqdm(self.ids_list):
        #         if is_2d:
        #             image, label = read_data(data_id, task=task+"_2d")
        #         else:
        #             image, label = read_data(data_id, task=task)
        #         self.data_list[data_id] = (image, label)

    def __len__(self):
        return self.repeat

    def _get_data(self, data_id):
        if self.is_val:
            image, label = self.data_list[data_id]
        else:
            if self.is_2d:
                image, label = read_data(data_id, task=self.task+"_2d")
            else:
                image, label = read_data(data_id, task=self.task)
        return data_id, image, label


    def __getitem__(self, index):
        index = index % len(self.ids_list)
        data_id = self.ids_list[index]
        _, image, label = self._get_data(data_id)
        if self.unlabeled: # <-- for safety
            label[:] = 0
        if "synapse" in self.task:
            image = image.clip(min=-75, max=275)

        elif "mnms" in self.task:
            p5 = np.percentile(image.flatten(), 0.5)
            p95 = np.percentile(image.flatten(), 99.5)
            image = image.clip(min=p5, max=p95)
        image = image.astype(np.float32)
        if self.need_norm:
            image = (image - image.min()) / (image.max() - image.min())
        label = label.astype(np.int8)
        sample = {'image': image, 'label': label}
        if self.transform:
            sample = self.transform(sample)
            
        if self.is_coarse:
            coarse_label = perturb_seg(sample['label'].numpy())
            sample['coarse_label'] = coarse_label
        return sample


class DatasetAllTasks_basemodel(DatasetAllTasks):
    '''
    use coarse mask generated by basemodel
    '''
    def _get_data(self, data_id):
        if self.is_val:
            image, label = self.data_list[data_id]
        else:
            image, coarse_label, label= read_data_coarse(data_id, task=self.task, full_path=self.full_path)
        return image, coarse_label, label


    def __getitem__(self, index):
        index = index % len(self.ids_list)
        data_id = self.ids_list[index]
        image, coarse_label, label = self._get_data(data_id)
        # print("============",image.shape,coarse_label.shape,label.shape)
        if self.unlabeled: # <-- for safety
            label[:] = 0
        if "synapse" in self.task:
            image = image.clip(min=-75, max=275)

        elif "mnms" in self.task:
            p5 = np.percentile(image.flatten(), 0.5)
            p95 = np.percentile(image.flatten(), 99.5)
            image = image.clip(min=p5, max=p95)
        if self.need_norm:
            image = (image - image.min()) / (image.max() - image.min())
        image = image.astype(np.float32)
        if 'oss' in self.task:
            #TODO currently net only support binary
            image = image.transpose(2,1,0)
            label = (label==1).astype(np.int8)
            # label = label.astype(np.int8)
        else:
            label = label.astype(np.int8)
            coarse_label = coarse_label.astype(np.int8)
        sample = {'image': image, 'label': label, 'coarse_label':coarse_label}

        if self.transform:
            sample = self.transform(sample)
            
        if self.is_coarse:
            coarse_label = perturb_seg(sample['label'].numpy())
            sample['coarse_label'] = coarse_label
        return sample
import os
class DatasetPatch(DatasetAllTasks_basemodel):
    def __init__(self, 
                patch_size,
                split='train', 
                num_cls=1, task="", 
                repeat=None, 
                transform=None, 
                unlabeled=False, 
                is_val=False, 
                is_2d=False, 
                is_coarse = True, 
                need_norm = False,
                full_path = None):
        super().__init__(split=split,
                        repeat=repeat,
                        unlabeled=unlabeled,
                        transform=transform,
                        task=task,
                        num_cls=num_cls,
                        is_coarse = False,
                        full_path = full_path)
        self.patch_size = patch_size
    
    def _get_data(self, data_id):
        if self.is_val:
            image, label = self.data_list[data_id]
        else:
            image, coarse_label, label= self.read_data_coarse(data_id, task=self.task)
        return image, coarse_label, label
    
    def read_data_coarse(self,data_id, task, norm_cfg = None, device = 'cuda:0'):
        config = Config(task)
        im_path = os.path.join(config.save_dir, f'npy_patch{self.patch_size}_0.7', f'{data_id}img.npy')
        cl_path = os.path.join(config.save_dir, f'npy_patch{self.patch_size}_0.7', f'{data_id}cl.npy')
        lb_path = os.path.join(config.save_dir, f'npy_patch{self.patch_size}_0.7', f'{data_id}lb.npy')
        if not os.path.exists(im_path) or not os.path.exists(cl_path) or not os.path.exists(lb_path):
            print(im_path)
            print(cl_path)
            print(lb_path)
            raise ValueError(data_id)
        image = np.load(im_path)
        label = np.load(lb_path)
        coarse_label = np.load(cl_path)
        
        if norm_cfg is not None:
            image = (image - norm_cfg['mean']) / norm_cfg['std']
            image = image.astype(np.float32)
            
            return torch.from_numpy(image).to(device), \
                torch.from_numpy(coarse_label).to(device), \
                    torch.from_numpy(label).to(device)
        return image, coarse_label, label
import time
import SimpleITK as sitk 
import sys
sys.path.append("/home/suk/3dOssSeg/code/data/other_process")
from denoisy2d import nlm_denoise
from guided_filter_data1 import apply_guided_filter
def read_nifti(path):
    itk_img = sitk.ReadImage(path)
    itk_arr = sitk.GetArrayFromImage(itk_img)
    return itk_arr
OSS_MAP = {
    'CG':1,
    'ZG':2,
    'DG':3,
}

def load_type(path):
    if path.endswith(".npy"):
        return(np.load(path))
    else:
        return(read_nifti(path))
from monai import transforms


class DatasetOss(DatasetAllTasks):
    def __init__(self, 
                split='train', 
                num_cls=1, task="", 
                repeat=None, 
                transform=None, 
                unlabeled=False, 
                is_val=False, 
                is_coarse = False, 
                oss_tag = 'DG',
                data_type = 'data1',
                full_path = None,
                model = "diffusion",
                base_model = None,
                diffusion_cfg = None):
        super().__init__(split=split,
                        repeat=repeat,
                        unlabeled=unlabeled,
                        transform=transform,
                        task=task,
                        num_cls=num_cls,
                        is_coarse = is_coarse,
                        full_path = full_path,
                        is_val = is_val)
        self.model=model
        self.oss_tag = oss_tag
        self.base_model = base_model
        self.flip = transforms.Flipd(["image", "label","coarse_label"],spatial_axis=2,allow_missing_keys=True)
        self.tmpcrop = transforms.CropForegroundd(keys=["image", "label","coarse_label","ref_label","dilate_label"], allow_missing_keys = True, source_key="ref_label", margin=16)

        self.data_type = data_type
        self.task = task
        
        self.diffusion_cfg = diffusion_cfg
        if diffusion_cfg is not None:
            betas = diffusion_cfg['betas']
            self.betas_cumprod = np.linspace(
                betas['start'], betas['stop'], 
                betas['num_timesteps'])
            self.timestep = betas['num_timesteps']
        
        # if self.is_val and self.model=="diffusion":
        #     print(self.ids_list)
        #     self.data_list = {}
        #     for data_id in tqdm(self.ids_list):
        #         image, label,coarse_label = self.read_data_oss_eval(data_id, task=task, oss_tag=oss_tag)
        #         self.data_list[data_id] = (image, label,coarse_label)
        # elif self.is_val and self.model=="other":
        #     print(self.ids_list)
        #     self.data_list = {}
        #     for data_id in tqdm(self.ids_list):
        #         image, label = self.read_data_oss_train(data_id, task=task, oss_tag=oss_tag)
        #         self.data_list[data_id] = (image, label)
    def read_data_oss_train(self,data_id,task,oss_tag):
        config = Config(task)
        im_path = os.path.join(config.save_dir, 'npy_image', f'{data_id}_image.npy')
        if self.data_type == "data1":
            if self.base_model is None:
                lb_path = os.path.join(config.save_dir, 'npy_label_sep', f'{data_id}_{oss_tag}_label.npy')
            elif self.base_model == "manual":
                # print(im_path)
                sp = im_path.rsplit("_",2)
                im_path = sp[0] + "_" + sp[-1]
                lb_path = f"/media/HDD/fanlinqian/ossicular/data1_process/label_manual1/{data_id}.nii.gz"
            elif self.base_model == "manual2":
                lb_path = f"/media/HDD/fanlinqian/ossicular/data1_process/label_manual2/{data_id}_label.nii.gz"
            elif self.base_model == "new_manual1":
                lb_path = f"/media/HDD/fanlinqian/ossicular/data1_process/new_manual1_mix/{data_id}_dilate.nii.gz"
            else:
                raise ValueError
        else:
            # lb_path = os.path.join(config.save_dir, 'npy_label_sep', f'{data_id}_{oss_tag}_label_filter.npy')
            lb_path = os.path.join(config.save_dir, 'label_manual',"filter_label3", f'{data_id}_label_filter.nii.gz')
        # if not os.path.exists(im_path) or not os.path.exists(lb_path):
        #     print(im_path)
        #     print(lb_path)
        #     raise ValueError(data_id)
        image = load_type(im_path)
        label = load_type(lb_path)
        return image,label
    def read_data_oss_eval(self,data_id,task,oss_tag):
        config = Config(task)
        im_path = os.path.join(config.save_dir, 'npy_image', f'{data_id}_image.npy')
        if self.data_type == 'data1':
            lb_path = os.path.join(config.save_dir, 'npy_label_sep', f'{data_id}_{oss_tag}_label.npy')
            if self.base_model is None:
                cl_path = f'/media/HDD/fanlinqian/ossicular/TGL_79/predictions/{data_id}.nii.gz'
            elif self.base_model == "manual1":
                cl_path = lb_path
                if "_" in data_id:
                    sp = im_path.rsplit("_",2)
                    im_path = sp[0] + "_" + sp[-1]
                    # sp = cl_path.rsplit("_",2)
                    # cl_path = sp[0] + "_" + sp[-1]
                    lb_path = f"/media/HDD/fanlinqian/ossicular/data1_process/label_manual1/{data_id}_label.nii.gz"
                    cl_path = lb_path.replace("label.nii.gz","orig_label.nii.gz")
                elif self.is_val is False:
                    lb_path = f"/media/HDD/fanlinqian/work_dirs_refiner/Exp_refiner_OSS/20241207-1733570705-diffusion_refiner_oss_diff/predictions/{data_id}_dilate.nii.gz"
                    
                # lb_path = f"/media/HDD/fanlinqian/work_dirs_refiner/Exp_refiner_OSS/20241109-1731155150-diffusion_refiner_oss/predictions/{data_id}_label.nii.gz"
            elif self.base_model == "manual2":
                cl_path = os.path.join(config.save_dir, 'npy_label_sep', f'{data_id}_{oss_tag}_label.npy')
                lb_path = f"/media/HDD/fanlinqian/ossicular/data1_process/label_manual2/{data_id}_label.nii.gz"
            elif self.base_model == "new_manual1":
                # lb_path = f"/media/HDD/fanlinqian/ossicular/data1_process/20250123-1737619804-diffusion_refiner_oss/{data_id}_dilate.nii.gz"
                # cl_path = f"/media/HDD/fanlinqian/ossicular/data1_process/20250123-1737619804-diffusion_refiner_oss/{data_id}_orig_label.nii.gz"
                lb_path = f"/media/HDD/fanlinqian/ossicular/data1_process/new_manual1_mix/{data_id}_dilate.nii.gz"
                cl_path = f"/media/HDD/fanlinqian/ossicular/data1_process/new_manual1_mix/{data_id}_orig_label.nii.gz"
            else:
                cl_path = f'{self.base_model}/predictions/{data_id}_pred.nii.gz'
                lb_path = f"/media/HDD/fanlinqian/ossicular/data1_process/label_manual2/{data_id}_label.nii.gz"
        elif self.data_type == "data2":
            # lb_path = os.path.join(config.save_dir, 'npy_label_sep', f'{data_id}_{oss_tag}_label_filter.npy')
            lb_path = os.path.join(config.save_dir, 'label_manual',"filter_label3", f'{data_id}_label_filter.nii.gz')
            if self.base_model is None:
                # cl_path = os.path.join(config.save_dir, 'coarse_label', f'{data_id}_{oss_tag}.nii.gz')
                cl_path = os.path.join(config.save_dir, 'npy_label_sep', f'{data_id}_{oss_tag}_label_filter.npy')
            else:
                cl_path = f'{self.base_model}/predictions/{data_id}_pred.nii.gz'
            # cl_path = lb_path #ADD
            # cl_path = os.path.join('/media/HDD/fanlinqian/work_dirs_ssl/Exp_refiner_OSS/20241028-1730115080-diffusion_refiner_oss/predictions_1/', f'{data_id}_pred.nii.gz')
        elif self.data_type == "data3":
            cl_path = f"/media/HDD/fanlinqian/ossicular/data3_253/filter_label/{data_id}_DG_label_filter.nii.gz"
            lb_path = f"/media/HDD/fanlinqian/ossicular/data3_253/filter_label/{data_id}_DG_label_filter.nii.gz"
            im_path = f"/media/HDD/fanlinqian/ossicular/data3_253/nii_Ori_253/Series{data_id}.nii.gz"
        elif self.data_type == "data4":
            cl_path = f"/media/HDD/fanlinqian/ossicular/data4/filter_label/{data_id}_DG_label_filter.nii.gz"
            lb_path = f"/media/HDD/fanlinqian/ossicular/data4/filter_label/{data_id}_DG_label_filter.nii.gz"
            im_path = f"/media/HDD/fanlinqian/ossicular/data4/nii_orig/Series{data_id}.nii.gz"
        # if not os.path.exists(im_path) or not os.path.exists(cl_path) or not os.path.exists(lb_path):
        #     print(im_path)
        #     print(cl_path)
        #     print(lb_path)
        #     raise ValueError(data_id)
        image = load_type(im_path)
        label = load_type(lb_path)
        coarse_label = load_type(cl_path)
        # print("DEBUG",coarse_label.max())
        # print(data_id)
        # print(label.shape,coarse_label.shape)
        # exit(0)
        if self.data_type == 'data1' and self.base_model is None:
            coarse_label = (coarse_label == OSS_MAP[oss_tag])
        return image,label,coarse_label.astype(np.int8)
    def read_reference_label(self,data_id,task,oss_tag):
        config = Config(task)
        if self.data_type == "data1":
            if "_" in data_id:
                sp = data_id.split("_")
                data_id = sp[0]
            lb_path = os.path.join(config.save_dir, 'npy_label_sep', f'{data_id}_{oss_tag}_label.npy')
        elif self.data_type == "data2":
            lb_path = os.path.join(config.save_dir, 'npy_label_sep', f'{data_id}_{oss_tag}_label_filter.npy')
        elif self.data_type == "data3":
            lb_path = f"/media/HDD/fanlinqian/ossicular/data3_253/filter_label/{data_id}_DG_label_filter.nii.gz"
        elif self.data_type == "data4":
            lb_path = f"/media/HDD/fanlinqian/ossicular/data4/filter_label/{data_id}_DG_label_filter.nii.gz"
        label = load_type(lb_path)
        return label
    def read_dilate_label(self,data_id):
        dilate_lb_path = f"/media/HDD/fanlinqian/ossicular/data1_process/label_manual1/{data_id}_dilate.nii.gz"
        dilate_label = load_type(dilate_lb_path)
        return dilate_label
    def other_process(self,data_id,sample):
        guided_image = apply_guided_filter(sample["ref_label"],sample["image"])
        sample["guided_image"] = guided_image
        return sample
    def __getitem__(self,index):
        index = index % len(self.ids_list)
        data_id = self.ids_list[index]
        # if self.data_type == "data4" or self.data_type == "data1":
        #     image,label,coarse_label = self.read_data_oss_eval(data_id, task=self.task, oss_tag=self.oss_tag)
        #     sample = {'image':image[None,...].astype(np.float32),
        #               'label':label[None,...].astype(np.int8),
        #               'coarse_label':coarse_label[None,...].astype(np.int8)}
        if self.is_val and self.model == "diffusion":
            image, label,coarse_label = self.read_data_oss_eval(data_id, task=self.task, oss_tag=self.oss_tag)
            sample = {'image':image[None,...].astype(np.float32),
                      'label':label[None,...].astype(np.int8),
                      'coarse_label':coarse_label[None,...].astype(np.int8)}
        elif self.is_val and self.model == "other":
            image, label = self.read_data_oss_train(data_id, task=self.task, oss_tag=self.oss_tag)
            sample = {'image':image[None,...].astype(np.float32),
                      'label':label[None,...].astype(np.int8),
                      }
        elif self.is_val is False:
            if  "random" in self.is_coarse:
                image, label, coarse_label = self.read_data_oss_eval(data_id, task=self.task, oss_tag=self.oss_tag)
                sample = {'image':image[None,...].astype(np.float32),
                      'label':label[None,...].astype(np.int8),
                      'coarse_label':coarse_label[None,...].astype(np.int8)}
            else:
                # image,label = self.read_data_oss_train(data_id,self.task,self.oss_tag)
                # sample = {'image':image[None,...].astype(np.float32),
                #           'label':label[None,...].astype(np.int8)}
                image,label = self.read_data_oss_train(data_id,self.task,self.oss_tag)
                
                sample = {'image':image[None,...].astype(np.float32),
                        'label':label[None,...].astype(np.int8),
                        }
        # sample["image"] = nlm_denoise(sample["image"][0])[None,...]
        sample["ref_label"] = self.read_reference_label(data_id,self.task,self.oss_tag)[None,...].astype(np.int8)
        # if self.is_val is False:
        #     # sample["dilate_label"] = self.read_dilate_label(data_id)[None,...].astype(np.int8)
        #     # print(sample["image"].shape,sample["label"].shape)
        #     sample = self.tmpcrop(sample)
        #     sample = self.other_process(data_id,sample)
        sample = self.transform(sample)
        # print(sample["coarse_label"].shape,sample["label"].shape)
        if self.is_coarse is True or 'random' in self.is_coarse:
            if  np.random.rand() > float(self.is_coarse.split('_')[-1]):
                coarse_label = perturb_seg(sample['label'].numpy().squeeze(),iou_target=(0.4,0.8))
                # coarse_label = perturb_seg_erode(sample['label'].numpy().squeeze(),iou_target=(0,0.7))
                # coarse_label = perturb_seg_dilate(sample['label'].numpy().squeeze())
                sample['coarse_label'] = torch.from_numpy(coarse_label[None,...]).to(torch.float)
        
        # tmp_mid=np.stack(perturb_seg_erode_all(sample['label'].numpy().squeeze()),axis=0)
        # sample["seg_mid"] = torch.from_numpy(tmp_mid).to(torch.float)
        if self.diffusion_cfg is not None:
            t = np.random.randint(self.timestep)
            sample["t"] = torch.tensor(t).long()
            sample["seg_mid"] = torch.from_numpy(perturb_seg_erode_mid(sample['label'].numpy().squeeze(),self.betas_cumprod[t])).to(torch.float)
        # if "R" in data_id and self.model == "diffusion":
        #     sample = self.flip(sample)
        # sample["data_id"] = data_id
        # keys_to_keep = ["image", "coarse_label", "label"]
        # new_sample = {key: sample[key] for key in keys_to_keep if key in sample}
        # return new_sample
        # sample["coarse_label"] = torch.zeros_like(sample["coarse_label"])
        return sample

class DatasetOss_noise(DatasetOss):
    def __init__(self, 
                 split='train', 
                 num_cls=1, 
                 task="", 
                 repeat=None, 
                 transform=None, 
                 unlabeled=False, 
                 is_val=False, 
                 is_coarse=False, 
                 oss_tag='DG',
                 data_type='data1',
                 full_path=None,
                 model="diffusion",
                 base_model=None,
                 diffusion_cfg=None,
                 ):
        super().__init__(split=split,
                         num_cls=num_cls,
                         task=task,
                         repeat=repeat,
                         transform=transform,
                         unlabeled=unlabeled,
                         is_val=is_val,
                         is_coarse=is_coarse,
                         oss_tag=oss_tag,
                         data_type=data_type,
                         full_path=full_path,
                         model=model,
                         base_model=base_model,
                         diffusion_cfg=diffusion_cfg)
        am=True
        patch_size=(64,64,64)
        self.noise_transform =transforms.Compose([
            transforms.CropForegroundd(keys=["label","coarse_label","ref_label"], allow_missing_keys = am, source_key="ref_label", margin=32),

            # transforms.RandSpatialCropd(keys=["image", "label","coarse_label","ref_label","dilate_label","guided_image"], roi_size=patch_size,allow_missing_keys = am,
            #                             # max_roi_size = patch_size,
            #                             random_size=False),
            transforms.CenterSpatialCropd(keys=["label","coarse_label","ref_label","dilate_label","guided_image"], allow_missing_keys = am, roi_size=patch_size),
            transforms.SpatialPadd(keys=["label","coarse_label","ref_label","dilate_label","guided_image"], allow_missing_keys = am, spatial_size=patch_size),

            transforms.NormalizeIntensityd(keys="image", nonzero=True, allow_missing_keys = am, channel_wise=True),
            transforms.RandFlipd(["image", "label","coarse_label","ref_label","dilate_label","guided_image"],spatial_axis=2,allow_missing_keys=True, prob=0.5),
            transforms.RandFlipd(["image", "label","coarse_label","ref_label","dilate_label","guided_image"],spatial_axis=1,allow_missing_keys=True, prob=0.5),
            transforms.RandFlipd(["image", "label","coarse_label","ref_label","dilate_label","guided_image"],spatial_axis=0,allow_missing_keys=True, prob=0.5),
            # transforms.RandScaleIntensityd(keys="image", factors=0.1, prob=0.3),
            # transforms.RandShiftIntensityd(keys="image", offsets=0.1, prob=0.3),
            transforms.ToTensord(keys=["image", "label","coarse_label","ref_label","dilate_label","guided_image"],allow_missing_keys = am,dtype=torch.float),
        ])
        self.oss2_ids_list = read_list(split="all", task="oss2")
    def __getitem__(self,index):
        index = index % len(self.ids_list)
        data_id = self.ids_list[index]
        # if self.data_type == "data4" or self.data_type == "data1":
        #     image,label,coarse_label = self.read_data_oss_eval(data_id, task=self.task, oss_tag=self.oss_tag)
        #     sample = {'image':image[None,...].astype(np.float32),
        #               'label':label[None,...].astype(np.int8),
        #               'coarse_label':coarse_label[None,...].astype(np.int8)}
        if self.is_val and self.model == "diffusion":
            image, label,coarse_label = self.read_data_oss_eval(data_id, task=self.task, oss_tag=self.oss_tag)
            sample = {'image':image[None,...].astype(np.float32),
                      'label':label[None,...].astype(np.int8),
                      'coarse_label':coarse_label[None,...].astype(np.int8)}
        elif self.is_val and self.model == "other":
            image, label = self.read_data_oss_train(data_id, task=self.task, oss_tag=self.oss_tag)
            sample = {'image':image[None,...].astype(np.float32),
                      'label':label[None,...].astype(np.int8),
                      }
        elif self.is_val is False:
            if  "random" in self.is_coarse:
                image, label, coarse_label = self.read_data_oss_eval(data_id, task=self.task, oss_tag=self.oss_tag)
                sample = {'image':image[None,...].astype(np.float32),
                      'label':label[None,...].astype(np.int8),
                      'coarse_label':coarse_label[None,...].astype(np.int8)}
            else:
                # image,label = self.read_data_oss_train(data_id,self.task,self.oss_tag)
                # sample = {'image':image[None,...].astype(np.float32),
                #           'label':label[None,...].astype(np.int8)}
                image,label = self.read_data_oss_train(data_id,self.task,self.oss_tag)
                
                sample = {'image':image[None,...].astype(np.float32),
                        'label':label[None,...].astype(np.int8),
                        }
        # sample["image"] = nlm_denoise(sample["image"][0])[None,...]
        sample["ref_label"] = self.read_reference_label(data_id,self.task,self.oss_tag)[None,...].astype(np.int8)
        # if self.is_val is False:
        #     # sample["dilate_label"] = self.read_dilate_label(data_id)[None,...].astype(np.int8)
        #     # print(sample["image"].shape,sample["label"].shape)
        #     sample = self.tmpcrop(sample)
        #     sample = self.other_process(data_id,sample)
        if np.random.rand()>0.8:
            img_path = f"/media/HDD/fanlinqian/ossicular/data1_process/noise_image/{data_id}_denoised_image.nii.gz"
            noise_id = self.oss2_ids_list[np.random.randint(0, 52)]
            noise_path = f"/media/HDD/fanlinqian/ossicular/data2_process/noise_image/{noise_id}_noise.nii.gz"
            noise_image = load_type(img_path)+load_type(noise_path)
            sample["image"] = noise_image[None,...].astype(np.float32)
            sample = self.noise_transform(sample)
        else:
            sample = self.transform(sample)
        # print(sample["coarse_label"].shape,sample["label"].shape)
        if self.is_coarse is True or 'random' in self.is_coarse:
            if  np.random.rand() > float(self.is_coarse.split('_')[-1]):
                coarse_label = perturb_seg(sample['label'].numpy().squeeze(),iou_target=(0.4,0.8))
                # coarse_label = perturb_seg_erode(sample['label'].numpy().squeeze(),iou_target=(0,0.7))
                # coarse_label = perturb_seg_dilate(sample['label'].numpy().squeeze())
                sample['coarse_label'] = torch.from_numpy(coarse_label[None,...]).to(torch.float)
        
        # tmp_mid=np.stack(perturb_seg_erode_all(sample['label'].numpy().squeeze()),axis=0)
        # sample["seg_mid"] = torch.from_numpy(tmp_mid).to(torch.float)
        if self.diffusion_cfg is not None:
            t = np.random.randint(self.timestep)
            sample["t"] = torch.tensor(t).long()
            sample["seg_mid"] = torch.from_numpy(perturb_seg_erode_mid(sample['label'].numpy().squeeze(),self.betas_cumprod[t])).to(torch.float)
        # if "R" in data_id and self.model == "diffusion":
        #     sample = self.flip(sample)
        # sample["data_id"] = data_id
        # keys_to_keep = ["image","label","coarse_label"]
        # new_sample = {key: sample[key] for key in keys_to_keep if key in sample}
        # return new_sample
        # sample["coarse_label"] = torch.zeros_like(sample["coarse_label"])
        return sample 


class DatasetOss_underover(DatasetOss):
    def __getitem__(self,index):
        index = index % len(self.ids_list)
        data_id = self.ids_list[index]
        # if self.data_type == "data4" or self.data_type == "data1":
        #     image,label,coarse_label = self.read_data_oss_eval(data_id, task=self.task, oss_tag=self.oss_tag)
        #     sample = {'image':image[None,...].astype(np.float32),
        #               'label':label[None,...].astype(np.int8),
        #               'coarse_label':coarse_label[None,...].astype(np.int8)}
        if self.is_val and self.model == "diffusion":
            image, label,coarse_label = self.read_data_oss_eval(data_id, task=self.task, oss_tag=self.oss_tag)
            sample = {'image':image[None,...].astype(np.float32),
                      'label':label[None,...].astype(np.int8),
                      'coarse_label':coarse_label[None,...].astype(np.int8)}
        elif self.is_val and self.model == "other":
            image, label = self.read_data_oss_train(data_id, task=self.task, oss_tag=self.oss_tag)
            sample = {'image':image[None,...].astype(np.float32),
                      'label':label[None,...].astype(np.int8),
                      }
        elif self.is_val is False:
            if  "random" in self.is_coarse:
                image, label, coarse_label = self.read_data_oss_eval(data_id, task=self.task, oss_tag=self.oss_tag)
                sample = {'image':image[None,...].astype(np.float32),
                      'label':label[None,...].astype(np.int8),
                      'coarse_label':coarse_label[None,...].astype(np.int8)}
            else:
                # image,label = self.read_data_oss_train(data_id,self.task,self.oss_tag)
                # sample = {'image':image[None,...].astype(np.float32),
                #           'label':label[None,...].astype(np.int8)}
                image,label = self.read_data_oss_train(data_id,self.task,self.oss_tag)
                
                sample = {'image':image[None,...].astype(np.float32),
                        'label':label[None,...].astype(np.int8),
                        }
        # sample["image"] = nlm_denoise(sample["image"][0])[None,...]
        sample["ref_label"] = self.read_reference_label(data_id,self.task,self.oss_tag)[None,...].astype(np.int8)
        # if self.is_val is False:
        #     # sample["dilate_label"] = self.read_dilate_label(data_id)[None,...].astype(np.int8)
        #     # print(sample["image"].shape,sample["label"].shape)
        #     sample = self.tmpcrop(sample)
        #     sample = self.other_process(data_id,sample)
        sample = self.transform(sample)
        # print(sample["coarse_label"].shape,sample["label"].shape)
        if self.is_coarse is True or 'random' in self.is_coarse:
            if  np.random.rand() > float(self.is_coarse.split('_')[-1]):
                # coarse_label = perturb_seg(sample['label'].numpy().squeeze(),iou_target=(0.4,0.8))
                under_label = perturb_seg_erode(sample['label'].numpy().squeeze(),iou_target=(0,0.7))
                over_label = perturb_seg_dilate(sample['label'].numpy().squeeze())
                sample['under_label'] = torch.from_numpy(under_label[None,...]).to(torch.float)
                sample['over_label'] = torch.from_numpy(over_label[None,...]).to(torch.float)
        
        # tmp_mid=np.stack(perturb_seg_erode_all(sample['label'].numpy().squeeze()),axis=0)
        # sample["seg_mid"] = torch.from_numpy(tmp_mid).to(torch.float)
        # if "R" in data_id and self.model == "diffusion":
        #     sample = self.flip(sample)
        # sample["data_id"] = data_id
        # keys_to_keep = ["image", "coarse_label", "label"]
        # new_sample = {key: sample[key] for key in keys_to_keep if key in sample}
        # return new_sample
        # sample["coarse_label"] = torch.zeros_like(sample["coarse_label"])
        return sample

class DatasetOss12(DatasetAllTasks):
    def __init__(self, 
                split='train', 
                num_cls=1, task="oss1", 
                repeat=None, 
                transform=None, 
                unlabeled=False, 
                is_val=False, 
                is_coarse = False, 
                oss_tag = 'DG',
                data_type = 'data1',
                full_path = None,
                model = "diffusion",
                base_model = None,
                diffusion_cfg = None):
        super().__init__(split=split,
                        repeat=repeat,
                        unlabeled=unlabeled,
                        transform=transform,
                        task=task,
                        num_cls=num_cls,
                        is_coarse = is_coarse,
                        full_path = full_path,
                        is_val = is_val)
        self.model=model
        self.oss_tag = oss_tag
        self.base_model = base_model
        self.flip = transforms.Flipd(["image", "label","coarse_label"],spatial_axis=2,allow_missing_keys=True)
        self.tmpcrop = transforms.CropForegroundd(keys=["image", "label","coarse_label","ref_label","dilate_label"], allow_missing_keys = True, source_key="ref_label", margin=16)

        self.data_type = data_type
        self.task = task
        print(self.ids_list)
        
    def __getitem__(self,index):
        index = index % len(self.ids_list)
        data_id = self.ids_list[index]
        
        if "1.3.6.1.4.1" in data_id:
            label = torch.tensor(1,dtype=torch.float)
            cl_path = os.path.join("/media/HDD/fanlinqian/ossicular/data2_process", 'npy_label_sep', f'{data_id}_DG_label_filter.npy')
            image = load_type(cl_path)
            image = self.transform(image[None,...])
        else:
            label = torch.tensor(0,dtype=torch.float)
            cl_path = os.path.join("/media/HDD/fanlinqian/ossicular/data1_process", 'npy_label_sep', f'{data_id}_DG_label.npy')
            image = load_type(cl_path)
            image = self.transform(image[None,...])
        return image,label
        
class DatasetLa(DatasetAllTasks):
    def __init__(self, 
                split='train', 
                num_cls=1, task="", 
                repeat=None, 
                transform=None, 
                unlabeled=False, 
                is_val=False, 
                is_coarse = False,
                patch = (32,32,32),
                full_path = None,
                pos_ball = False,
                need_sample_prob = False):
        super().__init__(split=split,
                        repeat=repeat,
                        unlabeled=unlabeled,
                        transform=transform,
                        task=task,
                        num_cls=num_cls,
                        is_coarse = is_coarse,
                        full_path = full_path,
                        is_val = is_val)
        self.patch = patch
        self.pos_ball = pos_ball
        self.need_sample_prob = need_sample_prob
        if self.is_val:
            print(self.ids_list)
            self.data_list = {}
            for data_id in tqdm(self.ids_list):
                image, label,coarse_label = self.read_data_oss_eval(data_id, task=task)
                self.data_list[data_id] = (image, label,coarse_label)
        else:
            self.all_coors, self.sample_prob = self.gen_coors()
        self.aug = transforms.RandRotate90d(keys=["image", "label", "coarse_label","image_pos"], prob=0.5, max_k=3)
    def filter_coors(self,patch_coors,mask):
        # print("debug",patch_coors,mask.shape)
        patch_coors_new = []
        for coor in patch_coors:
            patch_mask = mask[coor[1]:coor[4], coor[0]:coor[3], coor[2]:coor[5]]
            if (patch_mask.any()) and (not patch_mask.all()):
                patch_coors_new.append(coor)
        return torch.stack(patch_coors_new)
            
    def gen_coors(self):
        """
        use coarse to get dets
        """
        from data.gen_patches import get_dets
        print("==========load coors========")
        all_coors = {}
        if self.need_sample_prob:
            sample_prob = {}
        else:
            sample_prob = None
        for data_id in tqdm(self.ids_list):
            _, _, mask = self.read_data_oss_eval(data_id, task=self.task)
            patch_coors = get_dets(torch.tensor(mask),self.patch,0.3 if self.patch[0]==32 else 0.4)
            patch_coors = self.filter_coors(patch_coors,mask)
            all_coors[data_id] = patch_coors
            if self.need_sample_prob:
                sample_prob[data_id] = torch.ones(len(patch_coors))
        return all_coors,sample_prob
    def read_data_oss_train(self,data_id,task):
        config = Config(task)
        im_path = os.path.join(config.save_dir, 'npy', f'{data_id}_image.npy')
        lb_path = os.path.join(config.save_dir, 'npy', f'{data_id}_label.npy')
        if not os.path.exists(im_path) or not os.path.exists(lb_path):
            print(im_path)
            print(lb_path)
            raise ValueError(data_id)
        image = np.load(im_path)
        label = np.load(lb_path)
        return image,label
    def read_data_oss_eval(self,data_id,task):
        config = Config(task)
        im_path = os.path.join(config.save_dir, 'npy', f'{data_id}_image.npy')
        lb_path = os.path.join(config.save_dir, 'npy', f'{data_id}_label.npy')
        cl_path = os.path.join("/media/HDD/fanlinqian/work_dirs_othermodels/Exp_LA/20240914-1726327487-unert", 'predictions', f'{data_id}.nii.gz')
        if not os.path.exists(im_path) or not os.path.exists(cl_path) or not os.path.exists(lb_path):
            print(im_path)
            print(cl_path)
            print(lb_path)
            raise ValueError(data_id)
        image = np.load(im_path)
        label = np.load(lb_path)
        coarse_label = read_nifti(cl_path)
        # print(label.shape,coarse_label.shape)
        return image,label,coarse_label
    
    def get_image_pos(self,images,labels,clabels,patch_size,device,coor,sample_prob=None):

        # out = sitk.GetImageFromArray((mask>=0.6).cpu().numpy().astype(np.float32))
        # sitk.WriteImage(out, f'/media/HDD/fanlinqian/LASeg/boundary.nii.gz')
        # out = sitk.GetImageFromArray((labels[0,0]>=0.5).cpu().numpy().astype(np.float32))
        # sitk.WriteImage(out, f'/media/HDD/fanlinqian/LASeg/labels.nii.gz')
        # out = sitk.GetImageFromArray((images[0,0]).cpu().numpy().astype(np.float32))
        # sitk.WriteImage(out, f'/media/HDD/fanlinqian/LASeg/images.nii.gz')
        batch_size, resolution = images.shape[0], images.shape[2:]
        h,w,d = images.shape[2:]
        th,tw,td = patch_size[1], patch_size[0], patch_size[2]
        if sample_prob is None:
            tmp_idx = None
            tmpc = coor[torch.randint(0, len(coor), (1,)).item()]
        else:
            tmp_idx = torch.multinomial(sample_prob,1).item()
            tmpc = coor[tmp_idx]
            # print("DEBUG:",sample_prob,sample_prob.shape,tmp_idx,tmpc)
        i,j,k = tmpc[1].item(), tmpc[0].item(), tmpc[2].item()
        # i,j,k=ones_indices[torch.randint(0, ones_indices.size(0), (1,))][0].tolist()
        # i-=th//2
        # j-=tw//2
        # k-=td//2
        if i>h - th:
            i = h-th
        elif i<0:
            i=0
        if j>w - tw:
            j = w-tw
        elif j<0:
            j=0
        if k>d - td:
            k = d-td
        elif k<0:
            k=0
        i = torch.tensor([i])
        j = torch.tensor([j])
        k = torch.tensor([k])
        rows = torch.arange(th, dtype=torch.long, device=device) + i[:, None]
        columns = torch.arange(tw, dtype=torch.long, device=device) + j[:, None]
        depths = torch.arange(td, dtype=torch.long, device=device) + k[:, None]
        
        def crops(items):
            items = items.permute(1,0,2,3,4)
            items = items[:, torch.arange(batch_size)[:, None, None, None],
                            rows[:, :, None, None],
                            columns[:, None, :, None],
                            depths[:, None, None, :],
                            ]
            items = items.permute(1,0,2,3,4)
            return items
        if clabels is None:
            images,labels = crops(images),crops(labels)
        else:
            images,labels,clabels = crops(images),crops(labels),crops(clabels)

        x_pos = torch.arange(tw, dtype=torch.long, device=device)[None,:,None].repeat(th, 1, td).unsqueeze(0).unsqueeze(0).repeat(batch_size, 1, 1, 1, 1)
        y_pos = torch.arange(th, dtype=torch.long, device=device)[:,None,None].repeat(1, tw, td).unsqueeze(0).unsqueeze(0).repeat(batch_size, 1, 1, 1, 1)
        z_pos = torch.arange(td, dtype=torch.long, device=device)[None,None,:].repeat(th, tw, 1).unsqueeze(0).unsqueeze(0).repeat(batch_size, 1, 1, 1, 1)

        x_pos = x_pos + j.view(-1, 1, 1, 1, 1)
        y_pos = y_pos + i.view(-1, 1, 1, 1, 1)
        z_pos = z_pos + k.view(-1, 1, 1, 1, 1)


        if self.pos_ball:
            r = torch.sqrt(x_pos**2 + y_pos**2 + z_pos**2)
            theta = torch.arccos(z_pos / r)
            phi = torch.atan2(y_pos, x_pos)
            images_pos = torch.cat((r, theta, phi), dim=1)
        else:
            x_pos = (x_pos / (resolution[1] - 1) - 0.5) * 2.
            y_pos = (y_pos / (resolution[0] - 1) - 0.5) * 2.
            z_pos = (z_pos / (resolution[2] - 1) - 0.5) * 2.
            images_pos = torch.cat((x_pos, y_pos, z_pos), dim=1)
        return images,labels,clabels,images_pos,tmp_idx

    
    def __getitem__(self,index):
        """
        add norm and move it before transform
        """
        index = index % len(self.ids_list)
        data_id = self.ids_list[index]
        if self.is_val:
            image,label,coarse_label = self.data_list[data_id]
            sample = {'image':image[None,...].astype(np.float32),
                      'label':label[None,...].astype(np.int8),
                      'coarse_label':coarse_label[None,...].astype(np.int8)}
            sample["image"] = (sample["image"]-0.8892374)/1.0632252
            sample = self.transform(sample)
        else:
            # image,label = self.read_data_oss_train(data_id,self.task,self.oss_tag)
            # sample = {'image':image[None,...].astype(np.float32),
            #           'label':label[None,...].astype(np.int8)}
            image,label,coarse_label = self.read_data_oss_eval(data_id,self.task)
            sample = {'image':image[None,...].astype(np.float32),
                      'label':label[None,...].astype(np.int8),
                      'coarse_label':coarse_label[None,...].astype(np.int8)}
            # print("===========",sample["image"].shape,sample["label"].shape)
            sample["image"] = (sample["image"]-0.8892374)/1.0632252
            sample = self.transform(sample)
            if self.need_sample_prob is False:
                images,labels,clables,images_pos,sample_idx = self.get_image_pos(sample["image"][None,...],sample["label"][None,...],sample["coarse_label"][None,...],self.patch,'cpu',self.all_coors[data_id])
            else:
                images,labels,clables,images_pos,sample_idx = self.get_image_pos(sample["image"][None,...],sample["label"][None,...],sample["coarse_label"][None,...],self.patch,'cpu',self.all_coors[data_id],self.sample_prob[data_id])
            sample["image"] = images.squeeze(0)
            sample["label"] = labels.squeeze(0)
            sample["image_pos"] = images_pos.squeeze(0)
            sample["coarse_label"] = clables.squeeze(0)
            sample = self.aug(sample)
        
        # print("!!!!!!!!",sample["image"].shape,sample["image_pos"].shape)
        if self.is_coarse is True or (self.is_coarse == 'random' and np.random.rand() > 0.2):
            coarse_label = perturb_seg(sample['label'].squeeze().numpy(),iou_target=(0.5,0.8))
            sample['coarse_label'] = torch.from_numpy(coarse_label)[None,...].to(dtype=torch.float)
        elif self.is_coarse == 'white':
            sample['coarse_label'] = torch.ones_like(sample["label"],dtype=torch.float)
        elif self.is_coarse == 'noise':
            sample['coarse_label'] = (torch.rand_like(sample["label"])>=0.5).to(dtype=torch.float)

        # out = sitk.GetImageFromArray((sample['coarse_label']>=0.5).squeeze().cpu().numpy().astype(np.int8))
        # sitk.WriteImage(out, f'/media/HDD/fanlinqian/LASeg/debug/{data_id}_course.nii.gz')
        # out = sitk.GetImageFromArray((sample['label']>=0.5).squeeze().cpu().numpy().astype(np.int8))
        # sitk.WriteImage(out, f'/media/HDD/fanlinqian/LASeg/debug/{data_id}_labels.nii.gz')
        # out = sitk.GetImageFromArray((sample["image"]).squeeze().cpu().numpy().astype(np.float32))
        # sitk.WriteImage(out, f'/media/HDD/fanlinqian/LASeg/debug/{data_id}_images.nii.gz')
        # exit(0)
        if self.need_sample_prob is True:
            sample["data_id_and_idx"] = (data_id,sample_idx)
        return sample

